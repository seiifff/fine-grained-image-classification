# -*- coding: utf-8 -*-
"""train.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eDyfef_iTa87lZDetycTHwHP3RTHufLI
"""

!pip install --upgrade pip
!pip -q install timm torchmetrics albumentations opencv-python grad-cam

# ----------------------------
# INSTALL DEPENDENCIES
# ----------------------------
!pip install --upgrade pip -q
!pip install -q timm torchmetrics albumentations opencv-python grad-cam

# ----------------------------
# IMPORTS
# ----------------------------
import os, random, numpy as np, cv2, time, warnings
import torch, torch.nn as nn, torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
from tqdm.auto import tqdm
import timm
from torchmetrics.classification import MulticlassAccuracy
import albumentations as A
from albumentations.pytorch import ToTensorV2
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

warnings.filterwarnings("ignore")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("PyTorch:", torch.__version__, "| CUDA:", torch.cuda.is_available())

# ----------------------------
# CONFIG
# ----------------------------
CFG = {
    "dataset": "food101",   # options: "stanford_cars", "cub_200", "food101"
    "root": "/content/data",
    "img_size": 224,
    "batch_size": 64,
    "epochs": 20,
    "warmup_epochs": 2,
    "lr": 3e-4,
    "weight_decay": 1e-4,
    "label_smoothing": 0.05,
    "seed": 42,
    "num_workers": 2
}

torch.manual_seed(CFG["seed"])
np.random.seed(CFG["seed"])
random.seed(CFG["seed"])
os.makedirs(CFG["root"], exist_ok=True)

# ----------------------------
# AUGMENTATIONS (FIXED FOR ALBUMENTATIONS >=1.4)
# ----------------------------
train_aug = A.Compose([
    A.LongestMaxSize(max_size=max(256, CFG["img_size"])),
    A.PadIfNeeded(CFG["img_size"], CFG["img_size"], border_mode=cv2.BORDER_CONSTANT, value=0),
    A.RandomResizedCrop(size=(CFG["img_size"], CFG["img_size"]), scale=(0.7, 1.0), ratio=(0.8, 1.25)),
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5, border_mode=cv2.BORDER_CONSTANT),
    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05, p=0.5),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])

val_aug = A.Compose([
    A.LongestMaxSize(max_size=max(256, CFG["img_size"])),
    A.PadIfNeeded(CFG["img_size"], CFG["img_size"], border_mode=cv2.BORDER_CONSTANT, value=0),
    A.CenterCrop(height=CFG["img_size"], width=CFG["img_size"]),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])

# ----------------------------
# DATASET WRAPPER
# ----------------------------
class AlbumentationsWrapper(torch.utils.data.Dataset):
    def __init__(self, base_ds, augment):
        self.base = base_ds
        self.augment = augment

    def __len__(self):
        return len(self.base)

    def __getitem__(self, idx):
        img, y = self.base[idx]
        if not isinstance(img, np.ndarray):
            img = np.array(img)
        img = self.augment(image=img)["image"]
        return img, y

# ----------------------------
# DATASET LOADERS
# ----------------------------
def get_food101(root):
    from torchvision.datasets import Food101
    train_base = Food101(root=root, split="train", download=True)
    val_base = Food101(root=root, split="test", download=True)
    return train_base, val_base, len(train_base.classes), train_base.classes

def get_stanford_cars(root):
    try:
        from torchvision.datasets import StanfordCars
        train_base = StanfordCars(root=root, split="train", download=True)
        val_base = StanfordCars(root=root, split="test", download=True)
        classes = [f"class_{i}" for i in range(len(train_base.classes))] if train_base.classes is None else train_base.classes
        return train_base, val_base, len(classes), classes
    except Exception as e:
        print(f"StanfordCars not available: {e}. Falling back to Food101.")
        return get_food101(root)

def get_cub200(root):
    print("CUB-200 requires manual setup. Falling back to Food101.")
    return get_food101(root)

# Load dataset
if CFG["dataset"] == "stanford_cars":
    train_base, val_base, NUM_CLASSES, CLASS_NAMES = get_stanford_cars(CFG["root"])
elif CFG["dataset"] == "cub_200":
    train_base, val_base, NUM_CLASSES, CLASS_NAMES = get_cub200(CFG["root"])
else:
    train_base, val_base, NUM_CLASSES, CLASS_NAMES = get_food101(CFG["root"])

print("Classes:", NUM_CLASSES, "| Train:", len(train_base), "| Val:", len(val_base))

# Wrap datasets
train_ds = AlbumentationsWrapper(train_base, train_aug)
val_ds = AlbumentationsWrapper(val_base, val_aug)

train_dl = DataLoader(train_ds, batch_size=CFG["batch_size"], shuffle=True,
                      num_workers=CFG["num_workers"], pin_memory=True, persistent_workers=True)
val_dl = DataLoader(val_ds, batch_size=CFG["batch_size"], shuffle=False,
                    num_workers=CFG["num_workers"], pin_memory=True, persistent_workers=True)

# ----------------------------
# MODEL: SE-ResNet50
# ----------------------------
model = timm.create_model("seresnet50", pretrained=True, num_classes=NUM_CLASSES).to(device)

def set_trainable_backbone(m, trainable: bool):
    for name, p in m.named_parameters():
        if "fc" in name or "classifier" in name:
            p.requires_grad = True
        else:
            p.requires_grad = trainable

set_trainable_backbone(model, trainable=False)

criterion = nn.CrossEntropyLoss(label_smoothing=CFG["label_smoothing"])
optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),
                        lr=CFG["lr"], weight_decay=CFG["weight_decay"])
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG["epochs"])
scaler = torch.cuda.amp.GradScaler(enabled=(device.type == 'cuda'))

# ----------------------------
# TRAINING FUNCTIONS
# ----------------------------
def train_one_epoch(epoch):
    model.train()
    loss_sum = acc_sum = n = 0
    acc_metric = MulticlassAccuracy(num_classes=NUM_CLASSES).to(device)
    pbar = tqdm(train_dl, desc=f"Train E{epoch}")
    for xb, yb in pbar:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad(set_to_none=True)
        with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):
            logits = model(xb)
            loss = criterion(logits, yb)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        acc = acc_metric(logits, yb)
        loss_sum += loss.item() * xb.size(0)
        acc_sum += acc.item() * xb.size(0)
        n += xb.size(0)
        pbar.set_postfix(loss=f"{loss_sum/n:.4f}", acc=f"{acc_sum/n:.4f}")
    return loss_sum / n, acc_sum / n

@torch.no_grad()
def evaluate():
    model.eval()
    loss_sum = acc_sum = n = 0
    acc_metric = MulticlassAccuracy(num_classes=NUM_CLASSES).to(device)
    for xb, yb in val_dl:
        xb, yb = xb.to(device), yb.to(device)
        logits = model(xb)
        loss = criterion(logits, yb)
        acc = acc_metric(logits, yb)
        loss_sum += loss.item() * xb.size(0)
        acc_sum += acc.item() * xb.size(0)
        n += xb.size(0)
    return loss_sum / n, acc_sum / n

# ----------------------------
# TRAINING LOOP
# ----------------------------
best_acc = 0.0
for epoch in range(CFG["epochs"]):
    if epoch == CFG["warmup_epochs"]:
        set_trainable_backbone(model, trainable=True)
        optimizer = optim.AdamW(model.parameters(), lr=CFG["lr"], weight_decay=CFG["weight_decay"])

    tr_loss, tr_acc = train_one_epoch(epoch)
    va_loss, va_acc = evaluate()
    scheduler.step()
    print(f"Epoch {epoch:02d} | train {tr_loss:.4f}/{tr_acc:.4f} | val {va_loss:.4f}/{va_acc:.4f}")

    if va_acc > best_acc:
        best_acc = va_acc
        torch.save(model.state_dict(), "fgic_seresnet50.pt")
        print("âœ“ Saved best model @ acc:", best_acc)

print("Best Val Acc:", best_acc)

# ----------------------------
# GRAD-CAM VISUALIZATION
# ----------------------------
target_layers = [model.layer4[-1].conv3]  # Correct for seresnet50

def to_img01(t):
    mean = torch.tensor([0.485, 0.456, 0.406], device=t.device).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225], device=t.device).view(3, 1, 1)
    x = (t * std + mean).clamp(0, 1)
    return x

model.eval()
xb, yb = next(iter(val_dl))
xb, yb = xb.to(device), yb.to(device)
with torch.no_grad():
    logits = model(xb)
pred = logits.argmax(1)

cam = GradCAM(model=model, target_layers=target_layers, use_cuda=(device.type == 'cuda'))

plt.figure(figsize=(12, 8))
for i in range(min(8, len(xb))):
    img01 = to_img01(xb[i]).permute(1, 2, 0).cpu().numpy()
    grayscale_cam = cam(input_tensor=xb[i:i+1],
                        targets=[ClassifierOutputTarget(int(pred[i].item()))])[0]
    grayscale_cam = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-6)
    overlay = show_cam_on_image(img01, grayscale_cam, use_rgb=True)
    plt.subplot(2, 4, i+1)
    plt.imshow(overlay)
    plt.axis('off')
    plt.title(f"Pred:{pred[i].item()} True:{yb[i].item()}")
plt.tight_layout()
plt.show()

# ----------------------------
# FINAL EVALUATION
# ----------------------------
y_true, y_pred = [], []
model.eval()
with torch.no_grad():
    for xb, yb in val_dl:
        xb = xb.to(device)
        logits = model(xb)
        y_true.extend(yb.numpy().tolist())
        y_pred.extend(logits.argmax(1).cpu().numpy().tolist())

print(classification_report(y_true, y_pred, zero_division=0))
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
plt.imshow(cm, cmap='Blues')
plt.title("Confusion Matrix")
plt.colorbar()
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.show()

torch.save(model.state_dict(), "fgic_seresnet50.pt")
print("Saved -> fgic_seresnet50.pt")

# ----------------------------
# README
# ----------------------------
readme = f"""
# Fine-Grained Image Classification with Attention (SE-ResNet50 + Grad-CAM)

**Overview**
Built a fine-grained classifier with **SE-ResNet50** (channel attention) using **transfer learning** and strong **data augmentation**.
Includes **Grad-CAM** visualizations to interpret model focus on subtle class differences.

**Dataset**
- Configured for: **{CFG['dataset']}** (swap to `stanford_cars` or `cub_200`).
- Image size: {CFG['img_size']}px

**Training**
- Warmup freeze â†’ full fine-tuning
- Cosine LR, label smoothing={CFG['label_smoothing']}, AdamW, weight decay={CFG['weight_decay']}
- Mixed precision for speed

**Results**
- Best validation accuracy (run): *see notebook output*
- Confusion matrix and per-class report included
- Saved weights: `fgic_seresnet50.pt`

**Why attention?**
SE blocks reweight channels to emphasize discriminative part features (e.g., car grille/taillight; bird beak/wing pattern),
improving fine-grained recognition beyond plain CNN baselines.

**Tech**
Python, PyTorch, timm, Albumentations, OpenCV, torchmetrics, pytorch-grad-cam (Colab).
"""
print(readme)